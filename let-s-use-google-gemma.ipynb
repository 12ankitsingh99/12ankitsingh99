{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ankitsingh1299/let-s-use-google-gemma?scriptVersionId=164033869\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"attachments":{"005e13a9-23a2-4867-92b1-8ae849365adf.jpg":{"image/jpeg":"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"}},"cell_type":"markdown","id":"eb994657","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.007203,"end_time":"2024-02-23T17:50:45.121352","exception":false,"start_time":"2024-02-23T17:50:45.114149","status":"completed"},"tags":[]},"source":["# <mark>How to use Google Gemma</mark>\n","<span style=\"font-size:22px;color:purple\"> Thank you for having a look at my notebook - advice and feedback always welcomed!</span>\n","\n","   ![download.jpg](attachment:005e13a9-23a2-4867-92b1-8ae849365adf.jpg)\n","\n","Google has released Gemma 2B and 7B, a pair of open-source AI models that let developers use the research that went into its flagship Gemini more freely. While Gemini is a big closed AI model that directly competes with (and is nearly as powerful as) OpenAI’s ChatGPT, the lightweight Gemma will likely be suitable for smaller tasks like simple chatbots or summarizations.\n","\n","But what these models lack in complication, they may make up for in speed and cost of use. Despite their smaller size, Google claims Gemma models “surpass significantly larger models on key benchmarks” and are “capable of running directly on a developer laptop or desktop computer.” They will be available via Kaggle, Hugging Face, Nvidia’s NeMo, and Google’s Vertex AI. \n","\n"]},{"cell_type":"markdown","id":"58e75a3e","metadata":{"papermill":{"duration":0.006419,"end_time":"2024-02-23T17:50:45.13461","exception":false,"start_time":"2024-02-23T17:50:45.128191","status":"completed"},"tags":[]},"source":["# Fine-tune Gemma models in Keras using LoRA"]},{"cell_type":"markdown","id":"95aee81c","metadata":{"papermill":{"duration":0.006471,"end_time":"2024-02-23T17:50:45.14763","exception":false,"start_time":"2024-02-23T17:50:45.141159","status":"completed"},"tags":[]},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://ai.google.dev/gemma/docs/lora_tuning\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335\"><img src=\"https://ai.google.dev/images/cloud-icon.svg\" width=\"40\" />Open in Vertex AI</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","id":"6643c117","metadata":{"papermill":{"duration":0.006365,"end_time":"2024-02-23T17:50:45.160638","exception":false,"start_time":"2024-02-23T17:50:45.154273","status":"completed"},"tags":[]},"source":["## Overview\n","\n","Gemma is a family of lightweight, state-of-the art open models built from the same research and technology used to create the Gemini models.\n","\n","Large Language Models (LLMs) like Gemma have been shown to be effective at a variety of NLP tasks. An LLM is first pre-trained on a large corpus of text in a self-supervised fashion. Pre-training helps LLMs learn general-purpose knowledge, such as statistical relationships between words. An LLM can then be fine-tuned with domain-specific data to perform downstream tasks (such as sentiment analysis).\n","\n","LLMs are extremely large in size (parameters in the order of millions). Full fine-tuning (which updates all the parameters in the model) is not required for most applications because typical fine-tuning datasets are relatively much smaller than the pre-training datasets.\n","\n","[Low Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685){:.external} is a fine-tuning technique which greatly reduces the number of trainable parameters for downstream tasks by freezing the weights of the model and inserting a smaller number of new weights into the model. This makes training with LoRA much faster and more memory-efficient, and produces smaller model weights (a few hundred MBs), all while maintaining the quality of the model outputs.\n","\n","This tutorial walks you through using KerasNLP to perform LoRA fine-tuning on a Gemma 2B model using the [Databricks Dolly 15k dataset](https://www.kaggle.com/datasets/databricks/databricks-dolly-15k){:.external}. This dataset contains 15,000 high-quality human-generated prompt / response pairs specifically designed for fine-tuning LLMs."]},{"cell_type":"markdown","id":"b7aba05c","metadata":{"papermill":{"duration":0.006371,"end_time":"2024-02-23T17:50:45.173564","exception":false,"start_time":"2024-02-23T17:50:45.167193","status":"completed"},"tags":[]},"source":["## Setup"]},{"cell_type":"markdown","id":"a0f7d469","metadata":{"papermill":{"duration":0.006348,"end_time":"2024-02-23T17:50:45.186422","exception":false,"start_time":"2024-02-23T17:50:45.180074","status":"completed"},"tags":[]},"source":["### Get access to Gemma\n","\n","To complete this tutorial, you will first need to complete the setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). The Gemma setup instructions show you how to do the following:\n","\n","Gemma models are hosted by Kaggle. To use Gemma, request access on Kaggle:\n","\n","- Sign in or register at [kaggle.com](https://www.kaggle.com)\n","- Open the [Gemma model card](https://www.kaggle.com/models/google/gemma) and select _\"Request Access\"_\n","- Complete the consent form and accept the terms and conditions\n"]},{"cell_type":"markdown","id":"a90de2b8","metadata":{"papermill":{"duration":0.006386,"end_time":"2024-02-23T17:50:45.199363","exception":false,"start_time":"2024-02-23T17:50:45.192977","status":"completed"},"tags":[]},"source":["### Install dependencies\n","\n","Install Keras, KerasNLP, and other dependencies."]},{"cell_type":"markdown","id":"f059b9db","metadata":{"papermill":{"duration":0.006365,"end_time":"2024-02-23T17:50:45.212159","exception":false,"start_time":"2024-02-23T17:50:45.205794","status":"completed"},"tags":[]},"source":["## **Install and Import Libraries:**"]},{"cell_type":"code","execution_count":1,"id":"80f3fce4","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:50:45.227286Z","iopub.status.busy":"2024-02-23T17:50:45.226535Z","iopub.status.idle":"2024-02-23T17:51:13.721332Z","shell.execute_reply":"2024-02-23T17:51:13.720112Z"},"papermill":{"duration":28.50512,"end_time":"2024-02-23T17:51:13.723752","exception":false,"start_time":"2024-02-23T17:50:45.218632","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras-nlp in /opt/conda/lib/python3.10/site-packages (0.7.0)\r\n","Collecting keras-nlp\r\n","  Downloading keras_nlp-0.8.1-py3-none-any.whl.metadata (7.0 kB)\r\n","Requirement already satisfied: keras-core in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.1.7)\r\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (1.4.0)\r\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (1.24.4)\r\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (21.3)\r\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (2023.12.25)\r\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (13.7.0)\r\n","Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.1.8)\r\n","Requirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.1.6)\r\n","Requirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (2.15.0)\r\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-nlp) (2.31.0)\r\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-nlp) (4.66.1)\r\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-nlp) (0.0.7)\r\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core->keras-nlp) (3.10.0)\r\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-nlp) (3.1.1)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp) (3.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-nlp) (2.17.2)\r\n","Requirement already satisfied: tensorflow-hub>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras-nlp) (0.15.0)\r\n","Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras-nlp) (2.15.0)\r\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\r\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.6.3)\r\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (23.5.26)\r\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.4)\r\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\r\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (16.0.6)\r\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\r\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.0)\r\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.20.3)\r\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (69.0.3)\r\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.16.0)\r\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.4.0)\r\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.9.0)\r\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.14.1)\r\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.35.0)\r\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.51.1)\r\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.1)\r\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\r\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-nlp) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-nlp) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-nlp) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-nlp) (2023.11.17)\r\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.42.0)\r\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.26.1)\r\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.2.0)\r\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.5.2)\r\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.7.2)\r\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.0.1)\r\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.2.4)\r\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.3.0)\r\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.9)\r\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.3.1)\r\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.1.3)\r\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.1)\r\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.2.2)\r\n","Downloading keras_nlp-0.8.1-py3-none-any.whl (465 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.2/465.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: keras-nlp\r\n","  Attempting uninstall: keras-nlp\r\n","    Found existing installation: keras-nlp 0.7.0\r\n","    Uninstalling keras-nlp-0.7.0:\r\n","      Successfully uninstalled keras-nlp-0.7.0\r\n","Successfully installed keras-nlp-0.8.1\r\n","Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.15.0)\r\n","Collecting keras\r\n","  Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\r\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\r\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.24.4)\r\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\r\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.7)\r\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\r\n","Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras) (0.1.8)\r\n","Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\r\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\r\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\r\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n","Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: keras\r\n","  Attempting uninstall: keras\r\n","    Found existing installation: keras 2.15.0\r\n","    Uninstalling keras-2.15.0:\r\n","      Successfully uninstalled keras-2.15.0\r\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n","tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0mSuccessfully installed keras-3.0.5\r\n"]}],"source":["# Install or upgrade the keras-nlp package\n","!pip install -U keras-nlp\n","\n","# Install or upgrade the keras package\n","!pip install -U keras"]},{"cell_type":"code","execution_count":2,"id":"93d2226a","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:51:13.743663Z","iopub.status.busy":"2024-02-23T17:51:13.743334Z","iopub.status.idle":"2024-02-23T17:51:27.077558Z","shell.execute_reply":"2024-02-23T17:51:27.076774Z"},"papermill":{"duration":13.346746,"end_time":"2024-02-23T17:51:27.079911","exception":false,"start_time":"2024-02-23T17:51:13.733165","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-23 17:51:15.574150: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-23 17:51:15.574267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-23 17:51:15.705568: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["# Import the entire keras library\n","import keras\n","\n","# Import the keras_nlp module\n","import keras_nlp\n","\n","# Import the numpy library and alias it as np for convenience\n","import numpy as np\n","\n","# Import the os module\n","import os"]},{"cell_type":"code","execution_count":3,"id":"ba3176f9","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:51:27.100803Z","iopub.status.busy":"2024-02-23T17:51:27.099909Z","iopub.status.idle":"2024-02-23T17:51:27.104331Z","shell.execute_reply":"2024-02-23T17:51:27.103455Z"},"papermill":{"duration":0.01678,"end_time":"2024-02-23T17:51:27.106269","exception":false,"start_time":"2024-02-23T17:51:27.089489","status":"completed"},"tags":[]},"outputs":[],"source":["# Set the KERAS_BACKEND environment variable to \"jax\"\n","os.environ[\"KERAS_BACKEND\"] = \"jax\""]},{"cell_type":"markdown","id":"f977d5ea","metadata":{"papermill":{"duration":0.009017,"end_time":"2024-02-23T17:51:27.124931","exception":false,"start_time":"2024-02-23T17:51:27.115914","status":"completed"},"tags":[]},"source":["**Explanation:**\n","\n","1. `gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")`: Creates an instance of GemmaCausalLM from the preset \"gemma_2b_en\".\n","\n","2. `gemma_lm.generate(\"Keras is a\", max_length=30)`: Generates text with a single prompt \"Keras is a\" and a maximum length of 30.\n","\n","3. `gemma_lm.generate([\"Keras is a\", \"I want to say\"], max_length=30)`: Generates text with batched prompts \"Keras is a\" and \"I want to say\", both having a maximum length of 30.\n","\n","4. The generated text results are then printed to the console.\n","\n","Keep in mind that the actual output will depend on the model's training data and the provided prompts. You may need to experiment with different prompts to explore the capabilities of the language model."]},{"cell_type":"markdown","id":"f9b98991","metadata":{"papermill":{"duration":0.008951,"end_time":"2024-02-23T17:51:27.142986","exception":false,"start_time":"2024-02-23T17:51:27.134035","status":"completed"},"tags":[]},"source":["## **Load and Compile the Model:**"]},{"cell_type":"code","execution_count":4,"id":"9373083d","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:51:27.162703Z","iopub.status.busy":"2024-02-23T17:51:27.162366Z","iopub.status.idle":"2024-02-23T17:52:54.247288Z","shell.execute_reply":"2024-02-23T17:52:54.246069Z"},"papermill":{"duration":87.097196,"end_time":"2024-02-23T17:52:54.249382","exception":false,"start_time":"2024-02-23T17:51:27.152186","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n","Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n","Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n","Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n","Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n","normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1708710773.495738      26 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","W0000 00:00:1708710773.558106      26 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1708710773.589318      26 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["Single Prompt Result:\n","Keras is a popular deep learning library for Python. It is easy to use and has a wide range of features. One of the features of\n"]}],"source":["# Create an instance of GemmaCausalLM from the preset\n","gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n","\n","# Generate text with a single prompt\n","single_prompt_result = gemma_lm.generate(\"Keras is a\", max_length=30)\n","\n","# Print the result for the single prompt\n","print(\"Single Prompt Result:\")\n","print(single_prompt_result)"]},{"cell_type":"code","execution_count":5,"id":"b82f8096","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:52:54.270224Z","iopub.status.busy":"2024-02-23T17:52:54.269906Z","iopub.status.idle":"2024-02-23T17:53:09.709656Z","shell.execute_reply":"2024-02-23T17:53:09.708313Z"},"papermill":{"duration":15.452444,"end_time":"2024-02-23T17:53:09.711829","exception":false,"start_time":"2024-02-23T17:52:54.259385","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["W0000 00:00:1708710789.008820      26 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\n","Batched Prompts Result:\n","Keras is a popular deep learning library for Python. It is easy to use and has a wide range of features. One of the features of\n","I want to say thank you to the staff at the <strong><em><u><strong><em><u><strong><em><u><strong><em><u><strong><em><u><strong><em>\n"]}],"source":["# Generate text with batched prompts\n","batched_prompt_result = gemma_lm.generate([\"Keras is a\", \"I want to say\"], max_length=30)\n","\n","# Print the result for the batched prompts\n","print(\"\\nBatched Prompts Result:\")\n","for result in batched_prompt_result:\n","    print(result)"]},{"cell_type":"code","execution_count":6,"id":"c4043700","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:53:09.735164Z","iopub.status.busy":"2024-02-23T17:53:09.734697Z","iopub.status.idle":"2024-02-23T17:53:09.768019Z","shell.execute_reply":"2024-02-23T17:53:09.76715Z"},"papermill":{"duration":0.047868,"end_time":"2024-02-23T17:53:09.769988","exception":false,"start_time":"2024-02-23T17:53:09.72212","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n","└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n","└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n","│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Assuming gemma_lm is a Keras model\n","gemma_lm.summary()"]},{"cell_type":"markdown","id":"822f1ab4","metadata":{"papermill":{"duration":0.010677,"end_time":"2024-02-23T17:53:09.791716","exception":false,"start_time":"2024-02-23T17:53:09.781039","status":"completed"},"tags":[]},"source":["## **Generate text**\n","\n","Now it's time to generate some text! The model has a generate method that generates text based on a prompt. The optional max_length argument specifies the maximum length of the generated sequence.\n","\n","Try it out with the prompt \"Why Rewa is famous?\"."]},{"cell_type":"code","execution_count":7,"id":"31bf0bf8","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:53:09.81556Z","iopub.status.busy":"2024-02-23T17:53:09.814964Z","iopub.status.idle":"2024-02-23T17:53:31.065833Z","shell.execute_reply":"2024-02-23T17:53:31.064854Z"},"papermill":{"duration":21.265797,"end_time":"2024-02-23T17:53:31.068432","exception":false,"start_time":"2024-02-23T17:53:09.802635","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'Why Rewa is famous?\\n\\nRewa is a city in the Indian state of Madhya Pradesh. It is the administrative headquarters of Rewa district. Rewa is famous for its Rewa Fort, which is a 17th-century fort built by the Rewa rulers. The fort is located on a hilltop and offers a panoramic view of the city. The fort is also home to a museum that showcases the history of the Rewa rulers.\\n\\nRewa is also famous for its Rewa mangoes, which are considered to be the best in the country. The mangoes are grown in the Rewa district and are known for their sweetness and flavour.\\n\\nRewa is also famous for its Rewa mangoes, which are considered to'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Create an instance of GemmaCausalLM using the from_preset method\n","gemma_lm.generate(\"Why Rewa is famous?\", max_length=150)              # REWA is my hometown that's why I asked to gemma, It is a city in the state of Madhya Pradesh, India."]},{"cell_type":"markdown","id":"ecd1b152","metadata":{"papermill":{"duration":0.010762,"end_time":"2024-02-23T17:53:31.091518","exception":false,"start_time":"2024-02-23T17:53:31.080756","status":"completed"},"tags":[]},"source":["**Explanation:**\n","\n","1. `prompt = \"What is the meaning of life?\"`: Defines the prompt for text generation. You can replace this with any prompt you'd like to use.\n","\n","2. `generated_text = gemma_lm.generate(prompt)`: Uses the `generate` method of the `gemma_lm` instance to generate text based on the provided prompt.\n","\n","3. `print(generated_text)`: Prints the generated text to the console.\n","\n","Keep in mind that the quality and relevance of the generated text will depend on the pre-training of the GemmaCausalLM model and the chosen prompt. Feel free to experiment with different prompts to see how the model responds.\n","\n"]},{"cell_type":"code","execution_count":8,"id":"1c79f20b","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:53:31.114688Z","iopub.status.busy":"2024-02-23T17:53:31.114394Z","iopub.status.idle":"2024-02-23T17:53:50.645076Z","shell.execute_reply":"2024-02-23T17:53:50.644112Z"},"papermill":{"duration":19.545167,"end_time":"2024-02-23T17:53:50.647563","exception":false,"start_time":"2024-02-23T17:53:31.102396","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["W0000 00:00:1708710829.344819      26 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["What is the meaning of life?\n","\n","The question is one of the most important questions in the world.\n","\n","It’s the question that has been asked by philosophers, theologians, and scientists for centuries.\n","\n","And it’s the question that has been asked by people who are looking for answers to their own lives\n"]}],"source":["# Define the prompt\n","prompt = \"What is the meaning of life?\"\n","\n","# Generate text based on the prompt\n","generated_text = gemma_lm.generate(prompt, max_length=64)\n","\n","# Print the generated text\n","print(generated_text)"]},{"cell_type":"code","execution_count":9,"id":"77071307","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:53:50.671818Z","iopub.status.busy":"2024-02-23T17:53:50.671267Z","iopub.status.idle":"2024-02-23T17:54:06.012788Z","shell.execute_reply":"2024-02-23T17:54:06.011833Z"},"papermill":{"duration":15.356177,"end_time":"2024-02-23T17:54:06.01524","exception":false,"start_time":"2024-02-23T17:53:50.659063","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["W0000 00:00:1708710844.454334      26 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"data":{"text/plain":["['What is the meaning of life?\\n\\nThe question is one of the most important questions in the world.\\n\\nIt’s the question that has been asked by philosophers, theologians, and scientists for centuries.\\n\\nAnd it’s the question that has been asked by people who are looking for answers to their own lives',\n"," 'How does the brain work?\\n\\nThe brain is the most complex organ in the human body. It is responsible for controlling all of the body’s functions, including breathing, heart rate, digestion, and more. The brain is also responsible for thinking, feeling, and making decisions.\\n\\nThe brain is made up']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["gemma_lm.generate(\n","    [\"What is the meaning of life?\",\n","     \"How does the brain work?\"],            \n","    max_length=64)"]},{"cell_type":"markdown","id":"f2d5a5cf","metadata":{"papermill":{"duration":0.012054,"end_time":"2024-02-23T17:54:06.040876","exception":false,"start_time":"2024-02-23T17:54:06.028822","status":"completed"},"tags":[]},"source":["**Optional: Try a different sampler**\n","\n","You can control the generation strategy for GemmaCausalLM by setting the sampler argument on compile(). By default, \"greedy\" sampling will be used.\n","\n","As an experiment, try setting a \"top_k\" strategy:\n"]},{"cell_type":"code","execution_count":10,"id":"d9ec4bf0","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:54:06.066867Z","iopub.status.busy":"2024-02-23T17:54:06.066502Z","iopub.status.idle":"2024-02-23T17:54:29.589905Z","shell.execute_reply":"2024-02-23T17:54:29.58868Z"},"papermill":{"duration":23.539256,"end_time":"2024-02-23T17:54:29.59227","exception":false,"start_time":"2024-02-23T17:54:06.053014","status":"completed"},"tags":[]},"outputs":[],"source":["# Compile the GemmaCausalLM model with a sampler\n","gemma_lm.compile(sampler=\"top_k\")\n","\n","# Generate text based on a prompt\n","generated_text = gemma_lm.generate(\"Tell me intresting about Stock Market?\", max_length=150)"]},{"cell_type":"code","execution_count":11,"id":"e00af6be","metadata":{"execution":{"iopub.execute_input":"2024-02-23T17:54:29.617672Z","iopub.status.busy":"2024-02-23T17:54:29.616858Z","iopub.status.idle":"2024-02-23T17:54:29.621548Z","shell.execute_reply":"2024-02-23T17:54:29.620672Z"},"papermill":{"duration":0.019753,"end_time":"2024-02-23T17:54:29.623919","exception":false,"start_time":"2024-02-23T17:54:29.604166","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Tell me intresting about Stock Market?\n","Stock Market is a place where people can buy and sell stocks. Stock markets are places where buyers and sellers of stocks meet to trade stocks.\n","Stock Market is a very interesting place to learn.\n","In the Stock Market, we buy shares of companies.\n","We sell those shares later to make a profit.\n","The price we pay for a share is called its <i><b>\"Purchase Price\"</b>.</i>\n","When we sell a share, we call the price we get when we sell the share <i>\"Sale Price.</i>\n","When I buy a share, I pay the <i>Purchase Price.</i>\n","When I sell, I get the money I paid to buy it.\n","\n"]}],"source":["# Print the generated text\n","print(generated_text)"]},{"cell_type":"markdown","id":"7ff31db0","metadata":{"papermill":{"duration":0.011334,"end_time":"2024-02-23T17:54:29.647156","exception":false,"start_time":"2024-02-23T17:54:29.635822","status":"completed"},"tags":[]},"source":["## **What's next**\n","\n","* Learn how to finetune a Gemma model. https://ai.google.dev/gemma/docs/lora_tuning\n","\n","* Learn how to perform distributed fine-tuning and inference on a Gemma model. https://ai.google.dev/gemma/docs/distributed_tuning\n","\n","* Learn how to use Gemma models with Vertex AI.https://cloud.google.com/vertex-ai/docs/generative-ai/open-models/use-gemma"]},{"cell_type":"markdown","id":"e3e709bd","metadata":{"papermill":{"duration":0.011121,"end_time":"2024-02-23T17:54:29.66967","exception":false,"start_time":"2024-02-23T17:54:29.658549","status":"completed"},"tags":[]},"source":["## **🚀 The best way to use Google Gemma 🚀**\n","\n","Dear,\n","\n","I hope this message finds you well.\n","\n","**1. Cast Your Vote:**\n","\n","Visit the competition platform and find my submissiona. Click on the \"Vote\" or \"Support\" button to cast your vote.\n","\n","**2. Share with Your Network:**\n","\n","Spread the word among your friends, family, and colleagues who may be interested in supporting my work.\n","\n","**3. Provide Feedback:**\n","\n","If you have any feedback or suggestions on my all notebooks, please feel free to share them with me. Your input is valuable and can help me improve. I am committed to making a positive impact in the field of Generative AI, and your support will bring me one step closer to achieving that goal.\n","\n","Thank you for taking the time to read this message, and I genuinely appreciate your support. Together, we can contribute to the field of data-driven cutting edge & fast growing technology Artificial Intelligent.\n","\n","If you have any questions or need more information about my Notebook, please don't hesitate to reach out to me. Your support means the world to me!\n","\n"]},{"cell_type":"markdown","id":"f53e9d46","metadata":{"papermill":{"duration":0.011101,"end_time":"2024-02-23T17:54:29.692209","exception":false,"start_time":"2024-02-23T17:54:29.681108","status":"completed"},"tags":[]},"source":["## **References**\n","\n","* [Get started with Gemma using KerasNLP](https://www.kaggle.com/code/nilaychauhan/get-started-with-gemma-using-kerasnlp)\n","* [Fine-tune Gemma models in Keras using LoRA](https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4483838,"sourceId":7684509,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":6216,"sourceId":11384,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelInstanceId":5171,"sourceId":11371,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":230.27967,"end_time":"2024-02-23T17:54:32.636499","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-23T17:50:42.356829","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}